{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProblemSet5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPT4mfskrT/vqe3n+wl+Utg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonOf1998/ProblemSet5/blob/main/ProblemSet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtDt63ThtGnC"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "working_dir = os.getcwd()\n",
        "local_zip = os.path.join(working_dir, 'main.zip')\n",
        "\n",
        "url = 'https://github.com/SonOf1998/ProblemSet5/archive/main.zip'\n",
        "urlretrieve(url,local_zip)\n",
        "\n",
        "# Extract zip file\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r') \n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "\n",
        "# Discard zip file\n",
        "if os.path.exists(local_zip):\n",
        "  os.remove(local_zip)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivnTPCPR2xW7"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def dataset():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "  y_train = to_categorical(y_train, 10)\n",
        "  y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "  # min-max normalization\n",
        "  x_train = x_train / 255\n",
        "  x_test  = x_test / 255\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl9jLSvnDB-Z",
        "outputId": "1b0b41b4-845d-4629-c8a7-65afb59eb410"
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.8)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.0.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.7.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.4.2)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (20.0.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (50.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.18.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JriuqsT8jvy"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, ReLU, LeakyReLU\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import hyperas\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV1gFCfSDqoQ"
      },
      "source": [
        "def create_model(x_train, x_test, y_train, y_test):\n",
        "\n",
        "  act = {{choice(['relu', 'leakyrelu'])}}\n",
        "  opti = {{choice(['rmsprop', 'adam', 'sgd'])}}\n",
        "  kernel_size = {{choice([2, 3])}}\n",
        "  dropout_1 = {{uniform(0, 0.5)}}\n",
        "  dropout_2 = {{uniform(0, 0.5)}}\n",
        "  dropout_3 = {{uniform(0, 0.5)}}\n",
        "  unit_size = {{choice([64, 128, 256])}}\n",
        "  batch_size = {{choice([16, 32, 64, 128, 256])}}\n",
        "\n",
        "  activation=None\n",
        "  if act == 'relu':\n",
        "    activation=ReLU()\n",
        "  elif act == 'leakyrelu':\n",
        "    activation=LeakyReLU()\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience=4)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, kernel_size, input_shape=(32, 32, 3)))\n",
        "  model.add(activation)\n",
        "  model.add(Conv2D(16, kernel_size))\n",
        "  model.add(activation)\n",
        "  model.add(MaxPooling2D(2))\n",
        "  model.add(Dropout(dropout_1))\n",
        "  model.add(Conv2D(32, kernel_size))\n",
        "  model.add(activation)\n",
        "  model.add(Conv2D(64, kernel_size))\n",
        "  model.add(activation)\n",
        "  model.add(MaxPooling2D(2))\n",
        "  model.add(Dropout(dropout_2))\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  model.add(Dense(unit_size))\n",
        "  model.add(activation)\n",
        "  model.add(Dropout(dropout_3))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  results = model.fit(x_train, y_train, batch_size=batch_size, epochs=100, verbose=0,\n",
        "                      validation_data=(x_test, y_test), callbacks=[early_stop], shuffle=True)\n",
        "\n",
        "  best_val_acc = np.amax(result.history['val_accuracy']) \n",
        "\n",
        "  with open('hyperas-log.csv', 'a') as csv_file:\n",
        "      csv_file.write(str(kernel_size) + ';')\n",
        "      csv_file.write(str(dropout_1) + ';')\n",
        "      csv_file.write(str(dropout_2) + ';')\n",
        "      csv_file.write(str(dropout_3) + ';')\n",
        "      csv_file.write(str(activation) + ';')\n",
        "      csv_file.write(str(unit_size) + ';')\n",
        "      csv_file.write(str(opti) + ';')\n",
        "      csv_file.write(str(batch_size) + ';')\n",
        "      csv_file.write(str(best_val_acc) + '\\n')\n",
        "\n",
        "\n",
        "  return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EXAYNfB-RVS"
      },
      "source": [
        "with open('hyperas-log.csv', 'w') as csv_file:\n",
        "  csv_file.write(\"kernel_size\" + ';')\n",
        "  csv_file.write(\"dropout_1\" + ';')\n",
        "  csv_file.write(\"dropout_2\" + ';')\n",
        "  csv_file.write(\"dropout_3\" + ';')\n",
        "  csv_file.write(\"activation\" + ';')\n",
        "  csv_file.write(\"unit_size\" + ';')\n",
        "  csv_file.write(\"opti\" + ';')\n",
        "  csv_file.write(\"batch_size\" + ';')\n",
        "  csv_file.write(\"best_val_acc\" + '\\n')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5ol1W_f0L1Oy",
        "outputId": "a0622883-f28c-46ae-cb41-d8784730fa03"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model, \n",
        "                                      data=dataset, algo=tpe.suggest, \n",
        "                                      max_evals=100, trials=Trials(), \n",
        "                                      notebook_name=\"ProblemSet5-main/ProblemSet5\", \n",
        "                                      verbose=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from urllib.request import urlretrieve\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import requests\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import zipfile\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.datasets import cifar10\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, ReLU, LeakyReLU\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.callbacks import EarlyStopping\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import hyperas\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'act': hp.choice('act', ['relu', 'leakyrelu']),\n",
            "        'opti': hp.choice('opti', ['rmsprop', 'adam', 'sgd']),\n",
            "        'kernel_size': hp.choice('kernel_size', [2, 3]),\n",
            "        'dropout_1': hp.uniform('dropout_1', 0, 0.5),\n",
            "        'dropout_1_1': hp.uniform('dropout_1_1', 0, 0.5),\n",
            "        'dropout_1_2': hp.uniform('dropout_1_2', 0, 0.5),\n",
            "        'unit_size': hp.choice('unit_size', [64, 128, 256]),\n",
            "        'batch_size': hp.choice('batch_size', [16, 32, 64, 128, 256]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
            "  3: \n",
            "  4: y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
            "  5: y_test =  tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
            "  6: \n",
            "  7: # min-max normalization\n",
            "  8: x_train = x_train / 255\n",
            "  9: x_test  = x_test / 255\n",
            " 10: \n",
            " 11: \n",
            " 12: \n",
            " 13: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3: \n",
            "   4:   act = space['act']\n",
            "   5:   opti = space['opti']\n",
            "   6:   kernel_size = space['kernel_size']\n",
            "   7:   dropout_1 = space['dropout_1']\n",
            "   8:   dropout_2 = space['dropout_1_1']\n",
            "   9:   dropout_3 = space['dropout_1_2']\n",
            "  10:   unit_size = space['unit_size']\n",
            "  11:   batch_size = space['batch_size']\n",
            "  12: \n",
            "  13:   activation=None\n",
            "  14:   if act == 'relu':\n",
            "  15:     activation=ReLU()\n",
            "  16:   elif act == 'leakyrelu':\n",
            "  17:     activation=LeakyReLU()\n",
            "  18: \n",
            "  19:   early_stop = EarlyStopping(monitor='val_accuracy', patience=4)\n",
            "  20: \n",
            "  21:   model = Sequential()\n",
            "  22:   model.add(Conv2D(16, kernel_size, input_shape=(32, 32, 3)))\n",
            "  23:   model.add(activation)\n",
            "  24:   model.add(Conv2D(16, kernel_size))\n",
            "  25:   model.add(activation)\n",
            "  26:   model.add(MaxPooling2D(2))\n",
            "  27:   model.add(Dropout(dropout_1))\n",
            "  28:   model.add(Conv2D(32, kernel_size))\n",
            "  29:   model.add(activation)\n",
            "  30:   model.add(Conv2D(64, kernel_size))\n",
            "  31:   model.add(activation)\n",
            "  32:   model.add(MaxPooling2D(2))\n",
            "  33:   model.add(Dropout(dropout_2))\n",
            "  34:   model.add(GlobalAveragePooling2D())\n",
            "  35:   model.add(Dense(unit_size))\n",
            "  36:   model.add(activation)\n",
            "  37:   model.add(Dropout(dropout_3))\n",
            "  38:   model.add(Dense(10, activation='softmax'))\n",
            "  39: \n",
            "  40:   model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['accuracy'])\n",
            "  41:   results = model.fit(x_train, y_train, batch_size=batch_size, epochs=100, verbose=0,\n",
            "  42:                       validation_data=(x_test, y_test), callbacks=[early_stop], shuffle=True)\n",
            "  43: \n",
            "  44:   best_val_acc = np.amax(result.history['val_accuracy']) \n",
            "  45: \n",
            "  46:   with open('hyperas-log.csv', 'a') as csv_file:\n",
            "  47:       csv_file.write(str(kernel_size) + ';')\n",
            "  48:       csv_file.write(str(dropout_1) + ';')\n",
            "  49:       csv_file.write(str(dropout_2) + ';')\n",
            "  50:       csv_file.write(str(dropout_3) + ';')\n",
            "  51:       csv_file.write(str(activation) + ';')\n",
            "  52:       csv_file.write(str(unit_size) + ';')\n",
            "  53:       csv_file.write(str(opti) + ';')\n",
            "  54:       csv_file.write(str(batch_size) + ';')\n",
            "  55:       csv_file.write(str(best_val_acc) + '\\n')\n",
            "  56: \n",
            "  57: \n",
            "  58:   return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}\n",
            "  59: \n",
            "Unexpected error: <class 'NameError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-37a17426c57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ProblemSet5-main/ProblemSet5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                       verbose=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtemp_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_fmin_fnct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected error: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/temp_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensorflow' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM5qzIf1My3J"
      },
      "source": [
        "import pandas\n",
        "df = pandas.read_csv('hyperas-log.csv', delimiter=';')\n",
        "df.sort_values(by=['best_val_acc'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}